{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training rapGPT: A Visually Friendly Guide\n",
    "\n",
    "This file is designed to provide a visually friendly process for training rapGPT. \n",
    "\n",
    "## Purpose of This File\n",
    "The purpose of this file is to offer detailed explanations of the training process, along with intermediate outputs to help understand how each step works. \n",
    "\n",
    "If you are looking for a script without the explanations and intermediate outputs, please refer to the corresponding script file: train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "#import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#custom functions\n",
    "from scripts import utils, train_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16  # how many independent sequences will be processed in parallel\n",
    "block_size = 512  # maximum context length (tokens)\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 200\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Eminem Lyrics Dataset from Kaggle\n",
    "\n",
    "## Overview\n",
    "\n",
    "The dataset contains information about Eminem's songs. The data consists of the following 5 columns:\n",
    "\n",
    "1. **Album Name**: The name of the album the song belongs to.\n",
    "2. **Song Name**: The name of the song.\n",
    "3. **Song Lyrics**: The lyrics of the song.\n",
    "4. **Album URL**: The URL of the album.\n",
    "5. **Song Views**: The number of views the song has received.\n",
    "6. **Release Date**: The date when the song was released.\n",
    "\n",
    "For our purpose, we will focus on the **Song Lyrics** column and ignore the other columns.\n",
    "\n",
    "## Dataset Link\n",
    "\n",
    "You can access the dataset [here](https://www.kaggle.com/datasets/aditya2803/eminem-lyrics/data).\n",
    "\n",
    "## Steps for Processing the Dataset\n",
    "\n",
    "We will be using **Pandas** for data manipulation and extraction of song lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Album_Name</th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Album_URL</th>\n",
       "      <th>Views</th>\n",
       "      <th>Release_date</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Music To Be Murdered By: Side B</td>\n",
       "      <td>Alfred (Intro)</td>\n",
       "      <td>[Intro: Alfred Hitchcock]\\r\\nThus far, this al...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Music-to-be-m...</td>\n",
       "      <td>24.3K</td>\n",
       "      <td>December 18, 2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Music To Be Murdered By: Side B</td>\n",
       "      <td>Black Magic</td>\n",
       "      <td>[Chorus: Skylar Grey &amp; Eminem]\\r\\nBlack magic,...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Music-to-be-m...</td>\n",
       "      <td>180.6K</td>\n",
       "      <td>December 18, 2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Music To Be Murdered By: Side B</td>\n",
       "      <td>Alfredï¿½s Theme</td>\n",
       "      <td>[Verse 1]\\r\\nBefore I check the mic (Check, ch...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Music-to-be-m...</td>\n",
       "      <td>285.6K</td>\n",
       "      <td>December 18, 2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Music To Be Murdered By: Side B</td>\n",
       "      <td>Tone Deaf</td>\n",
       "      <td>[Intro]\\r\\nYeah, I'm sorry (Huh?)\\r\\nWhat did ...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Music-to-be-m...</td>\n",
       "      <td>210.9K</td>\n",
       "      <td>December 18, 2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Music To Be Murdered By: Side B</td>\n",
       "      <td>Book of Rhymes</td>\n",
       "      <td>[Intro]\\r\\nI don't smile, I don't frown, get t...</td>\n",
       "      <td>https://genius.com/albums/Eminem/Music-to-be-m...</td>\n",
       "      <td>193.3K</td>\n",
       "      <td>December 18, 2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Album_Name         Song_Name  \\\n",
       "0  Music To Be Murdered By: Side B    Alfred (Intro)   \n",
       "1  Music To Be Murdered By: Side B       Black Magic   \n",
       "2  Music To Be Murdered By: Side B  Alfredï¿½s Theme   \n",
       "3  Music To Be Murdered By: Side B         Tone Deaf   \n",
       "4  Music To Be Murdered By: Side B    Book of Rhymes   \n",
       "\n",
       "                                              Lyrics  \\\n",
       "0  [Intro: Alfred Hitchcock]\\r\\nThus far, this al...   \n",
       "1  [Chorus: Skylar Grey & Eminem]\\r\\nBlack magic,...   \n",
       "2  [Verse 1]\\r\\nBefore I check the mic (Check, ch...   \n",
       "3  [Intro]\\r\\nYeah, I'm sorry (Huh?)\\r\\nWhat did ...   \n",
       "4  [Intro]\\r\\nI don't smile, I don't frown, get t...   \n",
       "\n",
       "                                           Album_URL   Views  \\\n",
       "0  https://genius.com/albums/Eminem/Music-to-be-m...   24.3K   \n",
       "1  https://genius.com/albums/Eminem/Music-to-be-m...  180.6K   \n",
       "2  https://genius.com/albums/Eminem/Music-to-be-m...  285.6K   \n",
       "3  https://genius.com/albums/Eminem/Music-to-be-m...  210.9K   \n",
       "4  https://genius.com/albums/Eminem/Music-to-be-m...  193.3K   \n",
       "\n",
       "        Release_date Unnamed: 6  \n",
       "0  December 18, 2020        NaN  \n",
       "1  December 18, 2020        NaN  \n",
       "2  December 18, 2020        NaN  \n",
       "3  December 18, 2020        NaN  \n",
       "4  December 18, 2020        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"Raw Data/Eminem_Lyrics.csv\"\n",
    "data = pd.read_csv(PATH, sep='\\t', comment='#', encoding = \"ISO-8859-1\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Lyrics to a Text File\n",
    "Intermediary Files will be saved in case it may be used in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics have been written to Text File/eminem_lyrics.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'Text File/'\n",
    "lyrics_file_name = 'eminem_lyrics.txt'\n",
    "lyrics = data['Lyrics']\n",
    "\n",
    "# Write lyrics to the text file, each lyric on a new line\n",
    "with open(output_file_path + lyrics_file_name, 'w', encoding='utf-8') as f:\n",
    "    for lyric in lyrics:\n",
    "        f.write(lyric + '\\n')\n",
    "\n",
    "print(f\"Lyrics have been written to {output_file_path + lyrics_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lyrics are separated into Intro, Outro, Chorus, Verse, etc. <br><br>\n",
    "**We are only interested in the [Verse] part of the lyrics since it contains the 'rap' portion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open lyrics text file \n",
    "with open(output_file_path + lyrics_file_name, 'r', encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "# Use regex to capture everything after '[Verse ...]' and before the next section\n",
    "verse_only = re.findall(r'\\[Verse.*?\\]\\n(.*?)(?=\\n\\[\\w|\\Z)', text, re.DOTALL)\n",
    "# Join the found text into a single string\n",
    "verse_only = '\\n'.join(verse_only)\n",
    "\n",
    "verse_file_name = 'verse_only.txt'\n",
    "# Output the result\n",
    "with open(output_file_path+verse_file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(verse_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Text\n",
    "1. Remove unwanted characters but keep newlines\n",
    "2. Normalize multiple spaces to a single space\n",
    "3. Remove trailing spaces before newlines\n",
    "4. Normalize multiple newlines to a single newline\n",
    "5. Convert to lower case\n",
    "\n",
    "**We are keeping newlines since it:**\n",
    "\n",
    "1. **Preserves Structure and Rhythm:**\n",
    "   - Rap lyrics are often structured in lines with rhymes, rhythms, and pauses. Keeping newlines helps the model learn this structure, making the generated lyrics feel more natural and rhythmic.\n",
    "2. **Improves Readability:**\n",
    "   - If the model generates lyrics with line breaks, it will be easier to read and evaluate during testing or usage.\n",
    "3. **Captures Line-Level Context:**\n",
    "   - By retaining newlines, the model can learn dependencies between consecutive lines without treating them as a continuous block of text.\n",
    "4. **Helps During Post-Processing:**\n",
    "   - You can always remove or modify newlines later if needed, but adding them back after training might be harder since the original structure would have been lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 180104\n"
     ]
    }
   ],
   "source": [
    "cleaned_verse_only = utils.preprocess_text_with_newlines(verse_only)\n",
    "cleaned_verse_only[:100]\n",
    "cleaned_verse_file_name = 'cleaned_verse_only.txt'\n",
    "# Output the result\n",
    "with open(output_file_path+cleaned_verse_file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(cleaned_verse_only)\n",
    "    \n",
    "words = cleaned_verse_only.split()\n",
    "# Get the number of words\n",
    "num_words = len(words)\n",
    "print(f\"Number of words: {num_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt2 BPE Tokenizer will be used to encode the text (Not used for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Load the GPT-2 tokenizer\\ngpt_tokenizer = tiktoken.get_encoding(\"gpt2\")\\n# Tokenize the text\\ntokens = gpt_tokenizer.encode(cleaned_verse_only)\\n\\n# Decode the tokens back to text\\n#decoded_text = tokenizer.decode(tokens[:10])\\n#print(\"Decoded text:\", decoded_text)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Load the GPT-2 tokenizer\n",
    "gpt_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "# Tokenize the text\n",
    "tokens = gpt_tokenizer.encode(cleaned_verse_only)\n",
    "\n",
    "# Decode the tokens back to text\n",
    "#decoded_text = tokenizer.decode(tokens[:10])\n",
    "#print(\"Decoded text:\", decoded_text)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer Training Plan\n",
    "\n",
    "- **Tokenizer Choice**: \n",
    "  - The trained tokenizer will be used with a vocab size of **30,000**, which is typically used for a model with a **small corpus**.\n",
    "- **Corpus Size**:\n",
    "  - The corpus that will be used for training has a size of **180,104 words**\n",
    "- **Tokenizer Types**:\n",
    "  - The corpus will be trained using both **BPE (Byte Pair Encoding)** since the model architecture wilk be based on the GPT model\n",
    "- **File Location**:\n",
    "  - The **train_tokenizer** script is saved in the `scripts` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tokenizer\n",
    "bpe_tokenizer = train_tokens.train_tokenizer(input_files=[\"Text File/cleaned_verse_only.txt\"], vocab_size=30000, tokenizer_type=\"bpe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode **cleaned_verse_only** using the BPE tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPE Tokens: ['\\n', \"we're \", 'volatile ', \"i can't call it \", 'though', '\\n', \"it's like \", 'too ', 'large ', 'a ']\n",
      "Len of Tokens: 155430\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the rap lyrics using the trained tokenizer\n",
    "bpe_tokenized_output = bpe_tokenizer.encode(cleaned_verse_only)\n",
    "# Print the tokenized output\n",
    "print(\"BPE Tokens:\", bpe_tokenized_output.tokens[:10])  # Prints the list of token strings\n",
    "print(\"Len of Tokens:\",  len(bpe_tokenized_output.ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try decoding the first 10 ids to verify if decoder is working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we're volatile i can't call it though it's like too large a\n"
     ]
    }
   ],
   "source": [
    "#get the numerical ids of the encoded toknes\n",
    "bpe_ids = bpe_tokenized_output.ids\n",
    "#get tokenized lyrics\n",
    "tokenized_lyrics = bpe_tokenized_output.tokens\n",
    "#try decoding first 10 ids\n",
    "output = bpe_tokenizer.decode(bpe_ids[:10])\n",
    "#remove empty spaces\n",
    "cleaned_output = re.sub(r'\\s+', ' ', output).strip()\n",
    "#print output\n",
    "print(cleaned_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the data into test and validation sets\n",
    "90% of the data will be used for training, 10% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([139887]), torch.Size([15543]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data = utils.train_test_split(tokenizer_ids = bpe_ids, device= device)\n",
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup for rapGPT\n",
    "\n",
    "We will be creating batches to train the data in parallel:\n",
    "\n",
    "- **Blocksize** = 512 (Each batch will contain 512 tokens at once)\n",
    "- **Batch size** = 16 (This indicates how many independent sequences will be processed in parallel)\n",
    "\n",
    "(16 batches are chosen based on max performance of my GPU: RTX4080 with 16GB VRAM)\n",
    "\n",
    "This setup allows efficient training by processing multiple sequences simultaneously, taking advantage of parallelization, while keeping the block size manageable for memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 7211,  3014,  1572, 13526,  2069,  3196,   184,    42,    36,     4],\n",
       "        device='cuda:0'),\n",
       " tensor([ 3014,  1572, 13526,  2069,  3196,   184,    42,    36,     4,   616],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = utils.get_batch(data = train_data, block_size = block_size, batch_size = batch_size, device= device)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(X_train[1:31], y_train[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min input index: 4\n",
      "Max input index: 29968\n",
      "Vocab size: 30000\n"
     ]
    }
   ],
   "source": [
    "print(\"Min input index:\", X_train.min().item())\n",
    "print(\"Max input index:\", X_train.max().item())\n",
    "print(\"Vocab size:\", 30000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
